---
title: "Eric Graham Project 1 EDA"
author: "Eric Graham"
date: "2024-10-21"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(skimr)
library(corrplot)
library(e1071)
library(caret)
library(mltools)
library(data.table)
library(car)
library(class)
library(tidyverse)
library(ggthemes)
options(scipen=999)
```

# Initial look at data

After reading in the data, I use skim() to get a thorough summary (and confirm no missing values). I also dropped some variables that aren't useful for analysis (Over18 and StandardHours only have one value each). 

```{r}
df = read.csv("CaseStudy1-data.csv")
head(df)
skim(df)
colnames(df)
df = df[, !(names(df) %in% c("ID", "EmployeeCount", "EmployeeNumber", "Over18", "StandardHours"))]
```

## Overall attrition count

```{r}
attrition_count = sum(df$Attrition == "Yes")
print(attrition_count)
```

## Factoring categorical variables

I make the categorical variables (including Attrition) into factors for further analysis/testing.

```{r}
cat_vars = c("Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime")
df[cat_vars] = lapply(df[cat_vars], as.factor)
str(df)
```

# Categorical Variable Analysis

## Visualization of categorical variables

I broke out a dataframe for categorical variables which I looped over for visualization. A visual examination of the categorical variables reveals a few trends in attrition:

1. Sales Representative, Sales Executive, Laboratory Technician, and Research Scientist job roles seem to be the most affected by attrition.
2. Overtime workers and single workers also seem to be disproportionately represented affected by attrition. 

```{r warning=FALSE}
cat_vars = c("BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime")
df_cat = df %>% select(all_of(cat_vars))
for (i in 1:ncol(df_cat)) {
  col_name = colnames(df_cat)[i]
  container_df = data.frame(value = df_cat[, i], Attrition = df$Attrition)
  
  g = ggplot(data = container_df, aes(x = value, fill = Attrition)) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent_format()) +
    labs(x = col_name, y = "Proportion", fill = "Attrition") +
    ggtitle(paste("Percentage of Attrition by", col_name)) +
    scale_fill_few() +
    theme_few() +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8))
  
  print(g)
  
  g_2 = ggplot(data = container_df, aes(x = value, fill = Attrition)) +
    geom_bar(position = "stack") +
    labs(x = col_name, y = "Count", fill = "Attrition") +
    ggtitle(paste("Count of Attrition by", col_name)) +
    scale_fill_few() +
    theme_few() +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8))
  
  print(g_2)
}
```

## Chi-square tests for categorical variables

In addition to a visual analysis of the categorical values, I used chi-square tests to look for evidence of relationships between those categorical variables and Attrition. Our null hypothesis assumes that there is no relationship, so a low p-value would indicate evidence of a relationship with attrition. 

We see overwhelming evidence that OverTime, JobRole, and MaritalStatus are related to Attrition, and strong evidence that Department is related to Attrition. The p-value for BusinessTravel meets the threshold for a 95% confidence level, but is close enough that we can only say that the evidence suggests a relationship.

```{r warning=FALSE}
results = data.frame(Variable = character(), PValue = numeric(), stringsAsFactors = FALSE)
for (col in cat_vars) {
  test_result = chisq.test(table(df[[col]], df$Attrition))
  results = rbind(results, data.frame(Variable = col, PValue = test_result$p.value, Statistic = test_result$statistic))
}

results = results[order(results$PValue), ]

print(results)
```

## Visualizations for EDA presentation

In my EDA, I want to present visuals related to OverTime, JobRole, and MaritalStatus. Instead of using the ones from the loop (which include the camel-case variable names) I'm making specific graphs for these three.

```{r warning=FALSE}
g_ot_1 = ggplot(data = df, aes(x = OverTime, fill = Attrition)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Overtime", y = "Proportion", fill = "Attrition") +
  ggtitle(paste("Percentage of Attrition by Overtime")) +
  scale_fill_few() +
  theme_few() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8)) +
  scale_fill_manual(values = c("#779ecb", "#974c5e"))

print(g_ot_1)

g_ot_2 = ggplot(data = df, aes(x = OverTime, fill = Attrition)) +
  geom_bar(position = "stack") +
  labs(x = "Overtime", y = "Count", fill = "Attrition") +
  ggtitle(paste("Count of Attrition by Overtime")) +
  scale_fill_few() +
  theme_few() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8)) +
  scale_fill_manual(values = c("#779ecb", "#974c5e"))
  
print(g_ot_2)

g_ms_1 = ggplot(data = df, aes(x = MaritalStatus, fill = Attrition)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Marital Status", y = "Proportion", fill = "Attrition") +
  ggtitle(paste("Percentage of Attrition by Marital Status")) +
  scale_fill_few() +
  theme_few() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8)) +
  scale_fill_manual(values = c("#779ecb", "#974c5e"))

print(g_ms_1)

g_ms_2 = ggplot(data = df, aes(x = MaritalStatus, fill = Attrition)) +
  geom_bar(position = "stack") +
  labs(x = "Marital Status", y = "Count", fill = "Attrition") +
  ggtitle(paste("Count of Attrition by Marital Status")) +
  scale_fill_few() +
  theme_few() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8)) +
  scale_fill_manual(values = c("#779ecb", "#974c5e"))

print(g_ms_2)

g_jr_1 = ggplot(data = df, aes(x = JobRole, fill = Attrition)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Job Role", y = "Proportion", fill = "Attrition") +
  ggtitle(paste("Percentage of Attrition by Job Role")) +
  scale_fill_few() +
  theme_few() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8)) +
  scale_fill_manual(values = c("#779ecb", "#974c5e"))

print(g_jr_1)

g_jr_2 = ggplot(data = df, aes(x = JobRole, fill = Attrition)) +
  geom_bar(position = "stack") +
  labs(x = "Job Role", y = "Count", fill = "Attrition") +
  ggtitle(paste("Count of Attrition by Job Role")) +
  scale_fill_few() +
  theme_few() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8)) +
  scale_fill_manual(values = c("#779ecb", "#974c5e"))

print(g_jr_2)
```

# Numeric Variable Analysis

My approach to the numeric variables was to handle the discreet and continuous variables separately. 

## Visualization of continuous variables

A visualization of the distribution of the continuous variables shows a few trends:

1. Age is slightly right-skewed
2. DistanceFromHome, MonthlyIncome, PercentSalaryHike, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, and YearsWithCurrManager are all very right-skewed.

```{r}
continuous_vars = c("Age", "DailyRate", "DistanceFromHome", "HourlyRate", "MonthlyIncome", "MonthlyRate", "PercentSalaryHike", "TotalWorkingYears", "YearsAtCompany", "YearsInCurrentRole", "YearsSinceLastPromotion", "YearsWithCurrManager")

cont_df = df %>% select(all_of(continuous_vars))

for (i in 1:ncol(cont_df)) {
  col_name = colnames(cont_df)[i]
  container_df = data.frame(value = cont_df[, i]) 
  
  g_3 = ggplot(data = container_df, aes(x = value)) +
    geom_histogram(fill = "#EEDD88", bins = 30) +
    labs(x = col_name, y = "Count", title = paste("Histogram of", col_name)) +
    theme_few() +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8))

  print(g_3)

  g_4 = ggplot(data = container_df, aes(x = value, y = "")) +
    geom_boxplot(fill = "#EEDD88") +
    labs(x = col_name, y = "", title = paste("Boxplot of", col_name)) +
    theme_few() +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
  
  print(g_4)
}

```

## Visualization of discrete variables

I also wanted to examine the distribution of our discrete variables. As we see below JobLevel, NumCompaniesWorked, and StockOptionLevel, are all very right-skewed.

```{r}
discrete_vars = c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "NumCompaniesWorked", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "TrainingTimesLastYear", "WorkLifeBalance")

discrete_df = df %>% select(all_of(discrete_vars))

for (i in 1:ncol(discrete_df)) {
  col_name = colnames(discrete_df)[i]
  container_df = data.frame(value = discrete_df[, i]) 
  
  g_5 = ggplot(data = container_df, aes(x = as.factor(value))) +
    geom_bar(fill = "#7495B8") +
    labs(x = col_name, y = "Count", title = paste("Bar Chart of", col_name)) +
    theme_few() +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8))
  
  print(g_5)
}
```

## Correlation of numeric variables

This analysis of the numeric variables is going to be useful when we fit our model, because the Naive Bayes model assumes a normal distribution of continuous variables. Transformations may be helpful in getting the best results from an NB model. K Nearest Neighbors is non-parametric, and might handle the skewed values better without transformation. 

Of course, the greatest question about our numeric variables is whether they are can help predict employee attrition. I created a correlation matrix to quantify the correlation between both continuous and discrete variables with the Attrition variable. A few observations stand out:

1. None of the numeric variables are highly correlated to Attrition; the one with the highest positive correlation (DistanceFromHome) has a correlation coefficient of .087. The only other numeric variable with a correlation coefficient greater than .05 is NumCompaniesWorked (.061).
2. However, there are some numeric variables that have a stronger negative correlation coefficient. This gives us some potential insight into employee retention, and will be useful when fitting our model.

### Correlation matrix and plot for continuous variables

```{r}
cont_df$Attrition_num = as.numeric(df$Attrition)
corr_matrix = cor(cont_df)
attrition_corr = corr_matrix["Attrition_num", ]
attrition_corr_df = data.frame(Correlation = attrition_corr)
attrition_corr_df = attrition_corr_df %>%
  arrange(desc(Correlation))
print(attrition_corr_df)
corrplot(corr_matrix)
```

### Correlation matrix and plot for discrete variables

```{r}
discrete_df$Attrition_num = as.numeric(df$Attrition)
corr_matrix = cor(discrete_df)
attrition_corr = corr_matrix["Attrition_num", ]
attrition_corr_df = data.frame(Correlation = attrition_corr)
attrition_corr_df = attrition_corr_df %>%
  arrange(desc(Correlation))
print(attrition_corr_df)
corrplot(corr_matrix)

```

### Correlation among continuous variables

I also tested the continuous variables for correlation among each other. Again, this will be useful for fitting our model, so as to avoid redundant variables "voting" multiple times. The below relationships have a correlation coefficient of greater than .5, so I want to be mindful of them when tuning the predictive model.

```{r}
correlation_matrix = cor(cont_df, use = "complete.obs")
correlation_df = as.data.frame(as.table(correlation_matrix))
filtered_corr_df = correlation_df %>%
  filter(abs(Freq) >= 0.5 & Var1 != Var2)
print(filtered_corr_df)
```

## Visualizations of numeric data for EDA presentation

The correlation plots are a little crowded for the EDA presentation slide, so I created a barplot that just shows the most correlated variables.

```{r}
selected_vars = c("Age", "DistanceFromHome", "HourlyRate", "JobInvolvement", "JobLevel", "JobSatisfaction", "MonthlyIncome",  "NumCompaniesWorked", "PerformanceRating", "StockOptionLevel", "TotalWorkingYears", "YearsAtCompany", "YearsInCurrentRole", "YearsWithCurrManager")

selected_df = df %>% select(all_of(selected_vars))
selected_df$Attrition_numeric = as.numeric(df$Attrition)
corr_matrix = cor(selected_df)
attrition_corr = corr_matrix["Attrition_numeric", ]
attrition_corr_df = data.frame(Variable = names(attrition_corr)[-length(attrition_corr)], Correlation = attrition_corr[-length(attrition_corr)])
attrition_corr_df = attrition_corr_df %>% arrange(desc(Correlation))
attrition_corr_df

g_corr = ggplot(attrition_corr_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +
  geom_bar(stat = "identity", fill = "#7495B8") +
  coord_flip() +  # Flip coordinates to make it horizontal
  labs(x = "Variables", y = "Correlation with Attrition", title = "Correlations with Attrition") +
  theme_few()

print(g_corr)
```

I also created tables to highlight these correlations.

#### Positive Correlations

| Variable                   | Correlation |
| -------------------------- | ----------- |
| Distance from Home         | 0.0871363   |
| Number of Companies Worked | 0.0610189   |
| Hourly Rate                | 0.0365542   |
| Performance Rating         | 0.0153338   |

#### Negative Correlations

| Variable                   | Correlation |
| -------------------------- | ----------- |
| Job Involvement            | -0.187793   |
| Total Working Years        | -0.167206   |
| Job Level                  | -0.162136   |
| Years in Current Role      | -0.156216   |
| Monthly Income             | -0.154915   |
| Age                        | -0.149384   |
| Stock Option Level         | -0.14868    |
| Years with Current Manager | -0.146782   |
| Years at Company           | -0.128754   |
| Job Satisfaction           | -0.107521   |

# Recursive Feature Elimination and Variable Importance

In anticipation of model-fitting, I implemented the below code for Recursive Feature Elimination (RFE) from [Okan Bulut's post on Towards Data Science](https://towardsdatascience.com/effective-feature-selection-recursive-feature-elimination-using-r-148ff998e4f7). This tests for the variables that are most important to predicting Attrition, and provides a score for variable importance which we can visualize.

```{r}
# the next two code chunkes were based entirely on the work of Okal Bulut, see
# https://towardsdatascience.com/effective-feature-selection-recursive-feature-elimination-using-r-148ff998e4f7
control <- rfeControl(functions = rfFuncs, # random forest
                      method = "repeatedcv", # repeated cv
                      repeats = 5, # number of repeats
                      number = 10) # number of folds

x <- df %>%
  select(BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime, Age, DailyRate, DistanceFromHome, Education, EnvironmentSatisfaction, HourlyRate, JobInvolvement, JobLevel, JobSatisfaction, MonthlyIncome, MonthlyRate, NumCompaniesWorked, PercentSalaryHike, PerformanceRating, RelationshipSatisfaction, StockOptionLevel, TotalWorkingYears, TrainingTimesLastYear, WorkLifeBalance, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager) %>%
  as.data.frame()

y <- df$Attrition

set.seed(2021)
inTrain <- createDataPartition(y, p = .80, list = FALSE)[,1]

x_train <- x[ inTrain, ]
x_test  <- x[-inTrain, ]

y_train <- y[ inTrain]
y_test  <- y[-inTrain]

# Run RFE
result_rfe1 <- rfe(x = x_train, 
                   y = y_train, 
                   sizes = c(5, 10, 15, 20, 25, 30),
                   rfeControl = control)

# Print the results
result_rfe1

# Print the selected features
predictors(result_rfe1)

# Print the results visually
ggplot(data = result_rfe1, metric = "Accuracy") + theme_bw()
ggplot(data = result_rfe1, metric = "Kappa") + theme_bw()
```


```{r}
varimp_data <- data.frame(feature = row.names(varImp(result_rfe1))[1:30],
                          importance = varImp(result_rfe1)[1:30, 1])
varimp_data$importance <- scale(varimp_data$importance)
varimp_data
ggplot(data = varimp_data, 
       aes(x = reorder(feature, -importance), y = importance, fill = feature)) +
  geom_bar(stat="identity") + labs(x = "Features", y = "Variable Importance") +  
  theme_bw() + theme(legend.position = "none") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 8))
```

# Initial Fit of Naive Bayes Model

Though my exploratory data analysis and RFE have given me a lot of insight into how I might approach feature selection, I want to see how the model performs with a "kitchen sink" initial fitting. This will give us a baseline to which we can compare future iterations of the model.

```{r}
accuracy_container = numeric(100)
sensitivity_container = numeric(100)
specificity_container = numeric(100)
for (i in 1:100) {

  set.seed(i)
  training_flag = sample(nrow(df), size = .7*nrow(df))
  train_attrition = df[training_flag, ]
  test_attrition = df[-training_flag, ]

  attrition_model = naiveBayes(Attrition ~ BusinessTravel + Department + EducationField + Gender + JobRole + MaritalStatus + OverTime + Age + DailyRate + DistanceFromHome + Education + EnvironmentSatisfaction + HourlyRate + JobInvolvement + JobLevel + JobSatisfaction + MonthlyIncome + MonthlyRate + NumCompaniesWorked + PercentSalaryHike + PerformanceRating + RelationshipSatisfaction + StockOptionLevel + TotalWorkingYears + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager, data = train_attrition)
  attrition_prediction = predict(attrition_model, test_attrition)
  confusion_matrix = confusionMatrix(factor(attrition_prediction), factor(test_attrition$Attrition))
  
  accuracy_container[i] = confusion_matrix$overall['Accuracy']
  sensitivity_container[i] = confusion_matrix$byClass['Sensitivity']
  specificity_container[i] = confusion_matrix$byClass['Specificity']
}

mean(accuracy_container)
mean(sensitivity_container)
mean(specificity_container)
```

![Using all possible variables, the Naive Bayes model provides respectable performance!](itsalive.png)

# Initial Fit of K Nearest Neighbors Model

My KNN model struggles with specificity. Even narrowing the scope to a selection of highly relevant variables doesn't help, and testing with different k-values hasn't yielded any improvement. Further feature selection and engineering is needed to see if we can find a useful predictive model with KNN.

```{r}
k_value = 1

k_accuracy_container = numeric(100)
k_sensitivity_container = numeric(100)
k_specificity_container = numeric(100)

selected_vars = c("JobRole", "Age", "OverTime", "MaritalStatus", "Department", "DistanceFromHome", "NumCompaniesWorked", "MonthlyIncome", "YearsInCurrentRole", "TotalWorkingYears", "StockOptionLevel", "JobLevel", "JobInvolvement", "YearsAtCompany")

for (i in 1:100) {
  
  set.seed(i)
  training_flag = sample(nrow(df), size = 0.7 * nrow(df))
  train_attrition = df[training_flag, ]
  test_attrition = df[-training_flag, ]

  train_vars = train_attrition[, selected_vars]
  test_vars = test_attrition[, selected_vars]

  train_vars = sapply(train_vars, as.numeric)
  test_vars = sapply(test_vars, as.numeric)
  
  train_target = train_attrition$Attrition
  test_target = test_attrition$Attrition
  
  attrition_knn = knn(train = train_vars, test = test_vars, cl = train_target, k = k_value)
  
  confusion_matrix = confusionMatrix(factor(attrition_knn), factor(test_target))
  
  k_accuracy_container[i] = confusion_matrix$overall['Accuracy']
  k_sensitivity_container[i] = confusion_matrix$byClass['Sensitivity']
  k_specificity_container[i] = confusion_matrix$byClass['Specificity']
}

mean(k_accuracy_container)
mean(k_sensitivity_container)
mean(k_specificity_container)
```

![Even with selected variables and the best K value, this model is struggling!](itsalive2.png)